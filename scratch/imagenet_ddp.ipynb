{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate tensorboard for monitoring model performance\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, gc\n",
    "\n",
    "# Timing utilities\n",
    "start_time = None\n",
    "\n",
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer_and_print(local_msg):\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + local_msg)\n",
    "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
    "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=1\n",
    "gpus=2\n",
    "num_workers=10\n",
    "\n",
    "batch_size=256\n",
    "epochs=2\n",
    "\n",
    "torch.manual_seed(43)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataloader(gpu,world_size,batch_size,num_workers):\n",
    "# Prepare training data\n",
    "    train_transform = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    #datadir=os.environ['DATA_DIR']\n",
    "    datadir='/ibex/ai/home/shaima0d/tiny-imagenet-200'\n",
    "    \n",
    "    trainset = torchvision.datasets.ImageFolder(root=os.path.join(datadir,'train'),\n",
    "                                                transform=train_transform)\n",
    "    trainSampler = torch.utils.data.distributed.DistributedSampler(trainset,\n",
    "                                                               num_replicas=world_size,\n",
    "                                                               rank=gpu,\n",
    "                                                               shuffle=False)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False, \n",
    "                                          num_workers=num_workers,\n",
    "                                          pin_memory=False,\n",
    "                                          sampler=trainSampler)\n",
    "                                         \n",
    "\n",
    "    valset = torchvision.datasets.ImageFolder(root=os.path.join(datadir,'val'),\n",
    "                                              transform=val_transform)\n",
    "    valSampler = torch.utils.data.distributed.DistributedSampler(valset,\n",
    "                                                                  num_replicas=world_size,\n",
    "                                                                  rank=gpu,shuffle=False)\n",
    "    valloader = torch.utils.data.DataLoader(valset, \n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False, \n",
    "                                             num_workers=num_workers,\n",
    "                                             pin_memory=False,\n",
    "                                             sampler=valSampler)\n",
    "    return trainloader,valloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the shape of the training dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe above shows that we have a total of 50,000 pictures of 10 classes in training dataset. \n",
    "\n",
    "Setting the batch_size=4 means we that our input will be 4 pictures i.e. 4*(3x32x32) pixels fed to our model at a time.\n",
    "This implies that our training loop will do 50000/4 = 12500 trips across the PCIe bus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolutional Neural Network\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=torchvision.models.resnet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the network\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train (net,gpus,world_size,rank,epochs,batch_size):\n",
    "    gpu_id=rank\n",
    "    print(gpu_id)\n",
    "    \n",
    "    net.cuda(gpu_id)\n",
    "    net = nn.SyncBatchNorm.convert_sync_batchnorm(net)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu_id)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    local_rank = gpu_id #int(os.environ['LOCAL_RANK'])\n",
    "    trainloader, valloader = dataloader(gpu_id,world_size,\n",
    "                                        batch_size,\n",
    "                                        num_workers)\n",
    "    # Wrap model as DDP\n",
    "    net = torch.nn.parallel.DistributedDataParallel(net,device_ids=[local_rank],\n",
    "                                                   output_device=None, )\n",
    "    start_timer()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        trainloader.sampler.set_epoch(epoch)\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].cuda(gpu_id), data[1].cuda(gpu_id)\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i % 2) and (gpu_id == 0):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    end_timer_and_print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(net,gpus,epochs,batch_size):\n",
    "    world_size = 2\n",
    "    setup(rank, world_size)\n",
    "    train(net,gpus,world_size,rank,epochs,batch_size)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with mp.Pool(gpus) as pool:\n",
    "    print(pool.starmap(train, [(i,nr,gpus,world_size,epochs,batch_size) for i in range(gpus)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#if __name__ == '__main__':\n",
    "num_processes = 2\n",
    "net = Net()\n",
    "# NOTE: this is required for the ``fork`` method to work\n",
    "#net.share_memory()\n",
    "mp.set_start_method('forkserver')\n",
    "processes = []\n",
    "for rank in range(num_processes):\n",
    "    p = mp.Process(target=train, args=(net,nr,gpus,world_size,epochs,batch_size))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/csgv/machine_learning/2022.11/el7_cudnn8.2_cuda11.2_py3.8_env/machine_learning-module/env/lib/python3.9/site-packages/torch/cuda/memory.py:278: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "/sw/csgv/machine_learning/2022.11/el7_cudnn8.2_cuda11.2_py3.8_env/machine_learning-module/env/lib/python3.9/site-packages/torch/cuda/memory.py:278: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2] loss: 0.007\n",
      "[1,     4] loss: 0.007\n",
      "[1,     6] loss: 0.008\n",
      "[1,     8] loss: 0.008\n",
      "[1,    10] loss: 0.008\n",
      "[1,    12] loss: 0.008\n",
      "[1,    14] loss: 0.009\n",
      "[1,    16] loss: 0.009\n",
      "[1,    18] loss: 0.009\n",
      "[1,    20] loss: 0.009\n",
      "[1,    22] loss: 0.009\n",
      "[1,    24] loss: 0.010\n",
      "[1,    26] loss: 0.009\n",
      "[1,    28] loss: 0.010\n",
      "[1,    30] loss: 0.009\n",
      "[1,    32] loss: 0.009\n",
      "[1,    34] loss: 0.009\n",
      "[1,    36] loss: 0.009\n",
      "[1,    38] loss: 0.009\n",
      "[1,    40] loss: 0.009\n",
      "[1,    42] loss: 0.009\n",
      "[1,    44] loss: 0.009\n",
      "[1,    46] loss: 0.009\n",
      "[1,    48] loss: 0.008\n",
      "[1,    50] loss: 0.008\n",
      "[1,    52] loss: 0.008\n",
      "[1,    54] loss: 0.008\n",
      "[1,    56] loss: 0.008\n",
      "[1,    58] loss: 0.008\n",
      "[1,    60] loss: 0.008\n",
      "[1,    62] loss: 0.008\n",
      "[1,    64] loss: 0.008\n",
      "[1,    66] loss: 0.008\n",
      "[1,    68] loss: 0.008\n",
      "[1,    70] loss: 0.008\n",
      "[1,    72] loss: 0.008\n",
      "[1,    74] loss: 0.008\n",
      "[1,    76] loss: 0.008\n",
      "[1,    78] loss: 0.008\n",
      "[1,    80] loss: 0.007\n",
      "[1,    82] loss: 0.008\n",
      "[1,    84] loss: 0.008\n",
      "[1,    86] loss: 0.008\n",
      "[1,    88] loss: 0.008\n",
      "[1,    90] loss: 0.008\n",
      "[1,    92] loss: 0.008\n",
      "[1,    94] loss: 0.008\n",
      "[1,    96] loss: 0.008\n",
      "[1,    98] loss: 0.008\n",
      "[1,   100] loss: 0.008\n",
      "[1,   102] loss: 0.007\n",
      "[1,   104] loss: 0.008\n",
      "[1,   106] loss: 0.007\n",
      "[1,   108] loss: 0.007\n",
      "[1,   110] loss: 0.008\n",
      "[1,   112] loss: 0.007\n",
      "[1,   114] loss: 0.008\n",
      "[1,   116] loss: 0.008\n",
      "[1,   118] loss: 0.008\n",
      "[1,   120] loss: 0.007\n",
      "[1,   122] loss: 0.007\n",
      "[1,   124] loss: 0.007\n",
      "[1,   126] loss: 0.008\n",
      "[1,   128] loss: 0.008\n",
      "[1,   130] loss: 0.007\n",
      "[1,   132] loss: 0.007\n",
      "[1,   134] loss: 0.007\n",
      "[1,   136] loss: 0.007\n",
      "[1,   138] loss: 0.007\n",
      "[1,   140] loss: 0.007\n",
      "[1,   142] loss: 0.007\n",
      "[1,   144] loss: 0.008\n",
      "[1,   146] loss: 0.008\n",
      "[1,   148] loss: 0.007\n",
      "[1,   150] loss: 0.007\n",
      "[1,   152] loss: 0.007\n",
      "[1,   154] loss: 0.007\n",
      "[1,   156] loss: 0.007\n",
      "[1,   158] loss: 0.007\n",
      "[1,   160] loss: 0.007\n",
      "[1,   162] loss: 0.007\n",
      "[1,   164] loss: 0.007\n",
      "[1,   166] loss: 0.007\n",
      "[1,   168] loss: 0.007\n",
      "[1,   170] loss: 0.007\n",
      "[1,   172] loss: 0.007\n",
      "[1,   174] loss: 0.007\n",
      "[1,   176] loss: 0.007\n",
      "[1,   178] loss: 0.007\n",
      "[1,   180] loss: 0.007\n",
      "[1,   182] loss: 0.007\n",
      "[1,   184] loss: 0.007\n",
      "[1,   186] loss: 0.007\n",
      "[1,   188] loss: 0.007\n",
      "[1,   190] loss: 0.007\n",
      "[1,   192] loss: 0.007\n",
      "[1,   194] loss: 0.007\n",
      "[1,   196] loss: 0.007\n",
      "[2,     2] loss: 0.007\n",
      "[2,     4] loss: 0.007\n",
      "[2,     6] loss: 0.008\n",
      "[2,     8] loss: 0.007\n",
      "[2,    10] loss: 0.007\n",
      "[2,    12] loss: 0.007\n",
      "[2,    14] loss: 0.007\n",
      "[2,    16] loss: 0.007\n",
      "[2,    18] loss: 0.007\n",
      "[2,    20] loss: 0.007\n",
      "[2,    22] loss: 0.007\n",
      "[2,    24] loss: 0.007\n",
      "[2,    26] loss: 0.007\n",
      "[2,    28] loss: 0.007\n",
      "[2,    30] loss: 0.006\n",
      "[2,    32] loss: 0.006\n",
      "[2,    34] loss: 0.006\n",
      "[2,    36] loss: 0.006\n",
      "[2,    38] loss: 0.006\n",
      "[2,    40] loss: 0.006\n",
      "[2,    42] loss: 0.007\n",
      "[2,    44] loss: 0.006\n",
      "[2,    46] loss: 0.006\n",
      "[2,    48] loss: 0.006\n",
      "[2,    50] loss: 0.006\n",
      "[2,    52] loss: 0.006\n",
      "[2,    54] loss: 0.006\n",
      "[2,    56] loss: 0.006\n",
      "[2,    58] loss: 0.006\n",
      "[2,    60] loss: 0.006\n",
      "[2,    62] loss: 0.006\n",
      "[2,    64] loss: 0.006\n",
      "[2,    66] loss: 0.007\n",
      "[2,    68] loss: 0.007\n",
      "[2,    70] loss: 0.007\n",
      "[2,    72] loss: 0.007\n",
      "[2,    74] loss: 0.006\n",
      "[2,    76] loss: 0.007\n",
      "[2,    78] loss: 0.007\n",
      "[2,    80] loss: 0.007\n",
      "[2,    82] loss: 0.007\n",
      "[2,    84] loss: 0.007\n",
      "[2,    86] loss: 0.007\n",
      "[2,    88] loss: 0.007\n",
      "[2,    90] loss: 0.007\n",
      "[2,    92] loss: 0.007\n",
      "[2,    94] loss: 0.007\n",
      "[2,    96] loss: 0.007\n",
      "[2,    98] loss: 0.007\n",
      "[2,   100] loss: 0.007\n",
      "[2,   102] loss: 0.006\n",
      "[2,   104] loss: 0.007\n",
      "[2,   106] loss: 0.007\n",
      "[2,   108] loss: 0.007\n",
      "[2,   110] loss: 0.007\n",
      "[2,   112] loss: 0.007\n",
      "[2,   114] loss: 0.007\n",
      "[2,   116] loss: 0.007\n",
      "[2,   118] loss: 0.007\n",
      "[2,   120] loss: 0.007\n",
      "[2,   122] loss: 0.007\n",
      "[2,   124] loss: 0.007\n",
      "[2,   126] loss: 0.007\n",
      "[2,   128] loss: 0.007\n",
      "[2,   130] loss: 0.007\n",
      "[2,   132] loss: 0.007\n",
      "[2,   134] loss: 0.007\n",
      "[2,   136] loss: 0.007\n",
      "[2,   138] loss: 0.007\n",
      "[2,   140] loss: 0.007\n",
      "[2,   142] loss: 0.007\n",
      "[2,   144] loss: 0.007\n",
      "[2,   146] loss: 0.007\n",
      "[2,   148] loss: 0.007\n",
      "[2,   150] loss: 0.007\n",
      "[2,   152] loss: 0.007\n",
      "[2,   154] loss: 0.007\n",
      "[2,   156] loss: 0.007\n",
      "[2,   158] loss: 0.007\n",
      "[2,   160] loss: 0.007\n",
      "[2,   162] loss: 0.007\n",
      "[2,   164] loss: 0.007\n",
      "[2,   166] loss: 0.007\n",
      "[2,   168] loss: 0.007\n",
      "[2,   170] loss: 0.007\n",
      "[2,   172] loss: 0.007\n",
      "[2,   174] loss: 0.007\n",
      "[2,   176] loss: 0.007\n",
      "[2,   178] loss: 0.007\n",
      "[2,   180] loss: 0.007\n",
      "[2,   182] loss: 0.007\n",
      "[2,   184] loss: 0.007\n",
      "[2,   186] loss: 0.007\n",
      "[2,   188] loss: 0.007\n",
      "[2,   190] loss: 0.007\n",
      "[2,   192] loss: 0.007\n",
      "[2,   194] loss: 0.007\n",
      "[2,   196] loss: 0.007\n",
      "\n",
      "Finished Training\n",
      "Total execution time = 366.310 sec\n",
      "Max memory used by tensors = 22631131648 bytes\n",
      "\n",
      "Finished Training\n",
      "Total execution time = 366.331 sec\n",
      "Max memory used by tensors = 0 bytes\n"
     ]
    }
   ],
   "source": [
    "import multiprocess as mp\n",
    "num_processes = gpus\n",
    "# NOTE: this is required for the ``fork`` method to work\n",
    "net.share_memory()\n",
    "processes = []\n",
    "for rank in range(num_processes):\n",
    "    p = mp.Process(target=main, args=(net,gpus,epochs,batch_size))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
