{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training a Classifier\n",
    "\n",
    "This notebook is a first attempt to training a model on images of 10 classes from CIFAR10 dataset using PyTorch.\n",
    "We will be using a pre-defined Neural Network from Torchvision library of models to start with.\n",
    "\n",
    "## What about data?\n",
    "\n",
    "The data pipelines has 3 steps:\n",
    "1. Read image file from disk as numpy arrays -- (use Pillow library or Torchvision for preprocessed datasets with PIL images) \n",
    "2. Transform:\n",
    "    - Standardize the format of all images e.g. crop, resize, normalize etc\n",
    "    - convert numpy arrays to Tensors\n",
    "3. Batch multiple images together as input (and load in GPU memory if using GPU)\n",
    "\n",
    "For steps 1 to 3, PyTorch provides a convinient class called Dataloader.\n",
    "It support different input formats like image, videos and text, you can create a custom dataloader \n",
    "using this class and still benefit from the utility functions of the class.\n",
    "\n",
    "\n",
    "## Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalize the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "An AI framework provides library functions to implement the above steps. \n",
    "We are using PyTorch in our case but you can use any -- Tensorflow, Keras, MXNet, etc...  \n",
    "\n",
    "\n",
    "#### THIS NOTEBOOK IS ADAPTED FROM https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=cifar10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcitons for capturing time elapsed\n",
    "import time, gc\n",
    "\n",
    "# Timing utilities\n",
    "start_time = None\n",
    "\n",
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer_and_print(local_msg):\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + local_msg)\n",
    "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
    "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch, datetime, os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load CUDA AMP\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate tensorboard for monitoring model performance\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=1\n",
    "gpus=1\n",
    "num_workers=10\n",
    "\n",
    "batch_size=256\n",
    "epochs=2\n",
    "\n",
    "torch.manual_seed(43)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "#datadir=os.environ['DATA_DIR']\n",
    "datadir='/ibex/ai/home/shaima0d/tiny-imagenet-200'\n",
    "    \n",
    "trainset = torchvision.datasets.ImageFolder(root=os.path.join(datadir,'train'),\n",
    "                                                transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=num_workers,\n",
    "                                          pin_memory=True)\n",
    "                                         \n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root=os.path.join(datadir,'val'),\n",
    "                                              transform=val_transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, \n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True, \n",
    "                                             num_workers=num_workers,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "net=torchvision.models.resnet50()\n",
    "if torch.cuda.is_available:\n",
    "    device = 'cuda'\n",
    "    net.cuda(torch.cuda.current_device());\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "If trianing on GPUs, we can move the object for loss function to GPU memory as well \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a training loop which does the following:\n",
    "- Read from training dataset images transformed tensors as batches as **inputs**\n",
    "- load **inputs** to device memory if training on a GPU\n",
    "- feed **inputs** to CNN and run a forward pass \n",
    "- Apply loss function and run a backward propation of loss on each layer\n",
    "- Optimize weights using the optimizer \n",
    "- Print average loss for every 2000 images trained\n",
    "We iterate over these step for N epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/csgv/machine_learning/2022.11/el7_cudnn8.2_cuda11.2_py3.8_env/machine_learning-module/env/lib/python3.9/site-packages/torch/cuda/memory.py:278: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] : Train loss:0.021 | Validation loss:0.022\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "start_timer()\n",
    "writer = SummaryWriter(\"logs/min_%d\" %(datetime.datetime.now().minute))\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    # Train loop\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs= data[0].cuda()\n",
    "        labels= data[1].cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_acc = accuracy(outputs,labels)\n",
    "    train_loss = train_loss / len(trainloader.dataset)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss , epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc , epoch)\n",
    " \n",
    "    # Validation loop ( we won't backprop and optimize since this step is not training the model)\n",
    "#    net.eval()    \n",
    "#    val_loss = 0.0\n",
    "#    for i, data in enumerate(valloader, 0):\n",
    "#        # get the inputs; data is a list of [inputs, labels]\n",
    "#        inputs= data[0].cuda()\n",
    "#        labels= data[1].cuda()\n",
    "#        with torch.no_grad():\n",
    "#            outputs = net(inputs)\n",
    "#            loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() #* data[0].size(0)\n",
    "\n",
    "    val_acc = accuracy(outputs,labels)\n",
    "    val_loss = val_loss / len(valloader.dataset)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss , epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc , epoch)\n",
    "    print(f'[{epoch + 1}] : Train loss:{train_loss:.3f} | Validation loss:{val_loss:.3f}')\n",
    "\n",
    "\n",
    "    writer.flush\n",
    "    \n",
    "end_timer_and_print('Finished Training')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly save our trained model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
