{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcitons for capturing time elapsed\n",
    "import time, gc\n",
    "\n",
    "# Timing utilities\n",
    "start_time = None\n",
    "\n",
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer_and_print(local_msg):\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + local_msg)\n",
    "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
    "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/rl9g/dl/apps/pytorch/2.0.0/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/sw/rl9g/dl/apps/pytorch/2.0.0/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch, datetime, os\n",
    "\n",
    "# Essential packages for training an image classifier in PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.cuda import amp\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(43)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate tensorboard for monitoring model performance\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting infrastructure for training in a Jupyter notebook.\n",
    "In a python script version of the code, this section should be parsed in as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = 1\n",
    "gpus=1\n",
    "num_workers = 8\n",
    "batch_size=64\n",
    "epochs=2\n",
    "lr=1e-3\n",
    "momentum=0.9\n",
    "weight_decay=5e-4\n",
    "print_interval=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous utility funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    preds = outputs.argmax(dim=1)\n",
    "    return torch.sum(preds == labels).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "Add a data management section to load and transform data.\n",
    "Here we manage not only the data location but also how it is loaded into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "    ])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "    ])\n",
    "\n",
    "datadir=os.environ['DATA_DIR']\n",
    "trainset = torchvision.datasets.ImageFolder(root=os.path.join(datadir,'train'),\n",
    "                                                transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=num_workers,\n",
    "                                          pin_memory=True,\n",
    "                                          drop_last=False)                                       \n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root=os.path.join(datadir,'val'),\n",
    "                                              transform=val_transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, \n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False, \n",
    "                                             num_workers=num_workers,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-training\n",
    "net=torchvision.models.resnet50(weights=None,num_classes=200)\n",
    "# Transfer learning\n",
    "#net=torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Loss function and optimizer\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "If trianing on GPUs, we can move the object for loss function to GPU memory as well \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "    device = 'cuda'\n",
    "    net.cuda(torch.cuda.current_device());\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), \n",
    "                      lr=lr, \n",
    "                      momentum=momentum,\n",
    "                      weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable AMP\n",
    "Instantiate a wrapper to implement Automatic mixed precission during trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/rl9g/dl/apps/pytorch/2.0.0/lib/python3.9/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] :Loss (train, val):0.081, 0.094\n",
      "[2] :Loss (train, val):0.076, 0.097\n",
      "\n",
      "Finished Training\n",
      "Total execution time = 220.684 sec\n",
      "Max memory used by tensors = 5770486272 bytes\n"
     ]
    }
   ],
   "source": [
    "print('Starting the training')\n",
    "net.to(device)\n",
    "start_timer()\n",
    "writer = SummaryWriter(\"logs/experiment_%s\" %(os.environ['SLURM_JOBID']))\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    # Train loop\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs= data[0].cuda(non_blocking=True)\n",
    "        labels= data[1].cuda(non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        with torch.cuda.amp.autocast(enabled=True,\n",
    "                                     dtype=torch.float32):\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader.dataset.targets)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss , epoch)\n",
    " \n",
    "    # Validation loop ( we won't backprop and optimize since this step is not training the model)\n",
    "    net.eval()    \n",
    "    val_loss = 0.0\n",
    "    for i, data in enumerate(valloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs= data[0].cuda(non_blocking=True)        \n",
    "        labels= data[1].cuda(non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() \n",
    "    val_loss = val_loss / len(valloader.dataset.targets)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss , epoch)\n",
    "    print(f'[{epoch + 1}] :Loss (train, val):{train_loss:.3f}, {val_loss:.3f}')\n",
    "    writer.flush\n",
    "    \n",
    "end_timer_and_print('Finished Training')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "PATH = './tiny_imagenet.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
